# lecture_08
[Reddit discussion](https://www.reddit.com/r/IntroToDL/comments/d8p6rb/lecture_08_and_discussion/)

## Description:
  - Stochastic gradient descent
  - Acceleration
  - Overfitting and regularization
  - Choosing a divergence (loss) function
  - Batch normalization
  - Dropout

## Video:
[![lecture_08](https://img.youtube.com/vi/fChBkJ_UjRw/0.jpg)](https://www.youtube.com/watch?v=fChBkJ_UjRw)


## Slides:
  http://deeplearning.cs.cmu.edu/document/lecture/lec6,7.stochastic_gradient.fall19.pdf
